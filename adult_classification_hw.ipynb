{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17192015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "Epoch 1/8\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7776 - f1_score: 0.3038 - loss: 0.7380 - precision: 0.4474 - recall: 0.2797 - val_accuracy: 0.8154 - val_f1_score: 0.6237 - val_loss: 0.4423 - val_precision: 0.6101 - val_recall: 0.6499\n",
      "Epoch 2/8\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8131 - f1_score: 0.5402 - loss: 0.4318 - precision: 0.6667 - recall: 0.4992 - val_accuracy: 0.8250 - val_f1_score: 0.6162 - val_loss: 0.4074 - val_precision: 0.6529 - val_recall: 0.5947\n",
      "Epoch 3/8\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8210 - f1_score: 0.5769 - loss: 0.4106 - precision: 0.6902 - recall: 0.5378 - val_accuracy: 0.8262 - val_f1_score: 0.5898 - val_loss: 0.3958 - val_precision: 0.6799 - val_recall: 0.5333\n",
      "Epoch 4/8\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8178 - f1_score: 0.5614 - loss: 0.4017 - precision: 0.6685 - recall: 0.5227 - val_accuracy: 0.8222 - val_f1_score: 0.5421 - val_loss: 0.3947 - val_precision: 0.7134 - val_recall: 0.4490\n",
      "Epoch 5/8\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8243 - f1_score: 0.5718 - loss: 0.3931 - precision: 0.6756 - recall: 0.5334 - val_accuracy: 0.8257 - val_f1_score: 0.5690 - val_loss: 0.3935 - val_precision: 0.6987 - val_recall: 0.4921\n",
      "Epoch 6/8\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8237 - f1_score: 0.5763 - loss: 0.3912 - precision: 0.6727 - recall: 0.5360 - val_accuracy: 0.8274 - val_f1_score: 0.5926 - val_loss: 0.3854 - val_precision: 0.6868 - val_recall: 0.5315\n",
      "Epoch 7/8\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8246 - f1_score: 0.5770 - loss: 0.3905 - precision: 0.6757 - recall: 0.5422 - val_accuracy: 0.8242 - val_f1_score: 0.5512 - val_loss: 0.3874 - val_precision: 0.7165 - val_recall: 0.4589\n",
      "Epoch 8/8\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8283 - f1_score: 0.5912 - loss: 0.3803 - precision: 0.6901 - recall: 0.5522 - val_accuracy: 0.8233 - val_f1_score: 0.5428 - val_loss: 0.3862 - val_precision: 0.7204 - val_recall: 0.4464\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.8204 - f1_score: 0.5250 - loss: 0.3847 - precision: 0.7014 - recall: 0.4453\n",
      "\u001b[1m814/814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.8231 - f1_score: 0.5193 - loss: 0.3805 - precision: 0.7175 - recall: 0.4338\n",
      "Epoch 1/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7825 - f1_score: 0.3180 - loss: 0.7328 - precision: 0.4429 - recall: 0.2908 - val_accuracy: 0.8140 - val_f1_score: 0.4787 - val_loss: 0.4648 - val_precision: 0.7342 - val_recall: 0.3727\n",
      "Epoch 2/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8161 - f1_score: 0.5479 - loss: 0.4315 - precision: 0.6844 - recall: 0.5000 - val_accuracy: 0.8146 - val_f1_score: 0.4629 - val_loss: 0.4147 - val_precision: 0.7539 - val_recall: 0.3493\n",
      "Epoch 3/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8188 - f1_score: 0.5635 - loss: 0.4106 - precision: 0.6701 - recall: 0.5216 - val_accuracy: 0.7993 - val_f1_score: 0.3362 - val_loss: 0.4532 - val_precision: 0.8141 - val_recall: 0.2214\n",
      "Epoch 4/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8190 - f1_score: 0.5526 - loss: 0.4031 - precision: 0.6769 - recall: 0.5024 - val_accuracy: 0.8206 - val_f1_score: 0.6042 - val_loss: 0.3881 - val_precision: 0.6455 - val_recall: 0.5888\n",
      "Epoch 5/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8230 - f1_score: 0.5712 - loss: 0.3908 - precision: 0.6780 - recall: 0.5306 - val_accuracy: 0.8199 - val_f1_score: 0.6575 - val_loss: 0.3918 - val_precision: 0.6081 - val_recall: 0.7345\n",
      "Epoch 6/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8182 - f1_score: 0.5653 - loss: 0.3956 - precision: 0.6708 - recall: 0.5254 - val_accuracy: 0.7723 - val_f1_score: 0.6398 - val_loss: 0.4612 - val_precision: 0.5177 - val_recall: 0.8589\n",
      "Epoch 7/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8279 - f1_score: 0.5961 - loss: 0.3848 - precision: 0.6846 - recall: 0.5611 - val_accuracy: 0.8154 - val_f1_score: 0.4535 - val_loss: 0.4267 - val_precision: 0.7724 - val_recall: 0.3342\n",
      "Epoch 8/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8231 - f1_score: 0.5834 - loss: 0.3924 - precision: 0.6902 - recall: 0.5426 - val_accuracy: 0.7643 - val_f1_score: 0.6377 - val_loss: 0.4791 - val_precision: 0.5070 - val_recall: 0.8818\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.7545 - f1_score: 0.6192 - loss: 0.4881 - precision: 0.4935 - recall: 0.8847\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.7568 - f1_score: 0.6232 - loss: 0.4842 - precision: 0.4951 - recall: 0.8829\n",
      "Epoch 1/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7803 - f1_score: 0.3113 - loss: 0.7383 - precision: 0.4833 - recall: 0.2783 - val_accuracy: 0.7821 - val_f1_score: 0.1954 - val_loss: 0.4938 - val_precision: 0.6687 - val_recall: 0.1175\n",
      "Epoch 2/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8154 - f1_score: 0.5450 - loss: 0.4370 - precision: 0.6854 - recall: 0.4923 - val_accuracy: 0.8246 - val_f1_score: 0.5486 - val_loss: 0.4027 - val_precision: 0.7008 - val_recall: 0.4627\n",
      "Epoch 3/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8172 - f1_score: 0.5551 - loss: 0.4125 - precision: 0.6799 - recall: 0.5131 - val_accuracy: 0.7733 - val_f1_score: 0.1089 - val_loss: 0.5068 - val_precision: 0.5500 - val_recall: 0.0622\n",
      "Epoch 4/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8251 - f1_score: 0.5665 - loss: 0.3968 - precision: 0.6906 - recall: 0.5209 - val_accuracy: 0.7755 - val_f1_score: 0.6294 - val_loss: 0.4504 - val_precision: 0.5158 - val_recall: 0.8267\n",
      "Epoch 5/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8228 - f1_score: 0.5968 - loss: 0.3946 - precision: 0.6797 - recall: 0.5642 - val_accuracy: 0.7991 - val_f1_score: 0.6351 - val_loss: 0.4198 - val_precision: 0.5551 - val_recall: 0.7613\n",
      "Epoch 6/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8222 - f1_score: 0.5736 - loss: 0.3979 - precision: 0.6820 - recall: 0.5308 - val_accuracy: 0.7999 - val_f1_score: 0.3265 - val_loss: 0.4515 - val_precision: 0.7687 - val_recall: 0.2135\n",
      "Epoch 7/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8229 - f1_score: 0.5673 - loss: 0.3887 - precision: 0.6765 - recall: 0.5267 - val_accuracy: 0.8275 - val_f1_score: 0.5664 - val_loss: 0.3867 - val_precision: 0.6958 - val_recall: 0.4896\n",
      "Epoch 8/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8228 - f1_score: 0.5760 - loss: 0.3870 - precision: 0.6769 - recall: 0.5368 - val_accuracy: 0.8289 - val_f1_score: 0.6082 - val_loss: 0.3813 - val_precision: 0.6625 - val_recall: 0.5752\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.8223 - f1_score: 0.5908 - loss: 0.3882 - precision: 0.6635 - recall: 0.5569\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.8308 - f1_score: 0.6049 - loss: 0.3787 - precision: 0.6714 - recall: 0.5834\n",
      "Epoch 1/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7844 - f1_score: 0.3197 - loss: 0.7378 - precision: 0.4638 - recall: 0.2910 - val_accuracy: 0.8179 - val_f1_score: 0.5575 - val_loss: 0.4389 - val_precision: 0.6727 - val_recall: 0.4907\n",
      "Epoch 2/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8150 - f1_score: 0.5389 - loss: 0.4342 - precision: 0.6812 - recall: 0.4943 - val_accuracy: 0.7945 - val_f1_score: 0.3033 - val_loss: 0.4791 - val_precision: 0.8104 - val_recall: 0.1931\n",
      "Epoch 3/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8206 - f1_score: 0.5568 - loss: 0.4048 - precision: 0.6771 - recall: 0.5139 - val_accuracy: 0.7535 - val_f1_score: 0.6088 - val_loss: 0.4870 - val_precision: 0.4916 - val_recall: 0.8152\n",
      "Epoch 4/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8223 - f1_score: 0.5745 - loss: 0.4002 - precision: 0.6761 - recall: 0.5369 - val_accuracy: 0.7652 - val_f1_score: 0.0586 - val_loss: 0.5940 - val_precision: 0.3660 - val_recall: 0.0323\n",
      "Epoch 5/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8181 - f1_score: 0.5393 - loss: 0.4010 - precision: 0.6685 - recall: 0.4909 - val_accuracy: 0.8259 - val_f1_score: 0.5479 - val_loss: 0.3885 - val_precision: 0.7188 - val_recall: 0.4584\n",
      "Epoch 6/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8250 - f1_score: 0.5829 - loss: 0.3874 - precision: 0.6872 - recall: 0.5406 - val_accuracy: 0.7549 - val_f1_score: 0.6282 - val_loss: 0.4896 - val_precision: 0.4972 - val_recall: 0.8729\n",
      "Epoch 7/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8193 - f1_score: 0.5778 - loss: 0.3933 - precision: 0.6666 - recall: 0.5461 - val_accuracy: 0.7938 - val_f1_score: 0.2977 - val_loss: 0.4735 - val_precision: 0.7860 - val_recall: 0.1889\n",
      "Epoch 8/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8230 - f1_score: 0.5798 - loss: 0.3896 - precision: 0.6820 - recall: 0.5408 - val_accuracy: 0.7998 - val_f1_score: 0.3456 - val_loss: 0.4720 - val_precision: 0.8006 - val_recall: 0.2297\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.8042 - f1_score: 0.3381 - loss: 0.4647 - precision: 0.7310 - recall: 0.2347\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7987 - f1_score: 0.3280 - loss: 0.4635 - precision: 0.7229 - recall: 0.2274\n",
      "Epoch 1/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7880 - f1_score: 0.3322 - loss: 0.7348 - precision: 0.4890 - recall: 0.2971 - val_accuracy: 0.7680 - val_f1_score: 0.0458 - val_loss: 0.5952 - val_precision: 0.3039 - val_recall: 0.0252\n",
      "Epoch 2/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8142 - f1_score: 0.5417 - loss: 0.4339 - precision: 0.6780 - recall: 0.5018 - val_accuracy: 0.8163 - val_f1_score: 0.4546 - val_loss: 0.4188 - val_precision: 0.7594 - val_recall: 0.3341\n",
      "Epoch 3/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8190 - f1_score: 0.5780 - loss: 0.4075 - precision: 0.6836 - recall: 0.5432 - val_accuracy: 0.7569 - val_f1_score: 0.6273 - val_loss: 0.4795 - val_precision: 0.4947 - val_recall: 0.8753\n",
      "Epoch 4/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8214 - f1_score: 0.5787 - loss: 0.4010 - precision: 0.6751 - recall: 0.5443 - val_accuracy: 0.8163 - val_f1_score: 0.4536 - val_loss: 0.3991 - val_precision: 0.7584 - val_recall: 0.3345\n",
      "Epoch 5/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8210 - f1_score: 0.5804 - loss: 0.4020 - precision: 0.6852 - recall: 0.5400 - val_accuracy: 0.8236 - val_f1_score: 0.5614 - val_loss: 0.3884 - val_precision: 0.6838 - val_recall: 0.4883\n",
      "Epoch 6/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8159 - f1_score: 0.5723 - loss: 0.3972 - precision: 0.6707 - recall: 0.5418 - val_accuracy: 0.7784 - val_f1_score: 0.6416 - val_loss: 0.4480 - val_precision: 0.5228 - val_recall: 0.8476\n",
      "Epoch 7/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8214 - f1_score: 0.5905 - loss: 0.3895 - precision: 0.6709 - recall: 0.5670 - val_accuracy: 0.8059 - val_f1_score: 0.6425 - val_loss: 0.4045 - val_precision: 0.5726 - val_recall: 0.7463\n",
      "Epoch 8/8\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8238 - f1_score: 0.5869 - loss: 0.3863 - precision: 0.6800 - recall: 0.5472 - val_accuracy: 0.7878 - val_f1_score: 0.6509 - val_loss: 0.4356 - val_precision: 0.5372 - val_recall: 0.8435\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.7879 - f1_score: 0.6487 - loss: 0.4351 - precision: 0.5350 - recall: 0.8582\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - accuracy: 0.7868 - f1_score: 0.6384 - loss: 0.4367 - precision: 0.5344 - recall: 0.8309\n",
      "\n",
      "訓練集績效\n",
      "Loss: 0.4333116412162781\n",
      "Accuracy: 0.7882068157196045\n",
      "Precision: 0.6409599184989929\n",
      "Recall: 0.5386527180671692\n",
      "F1 Score: 0.8322943449020386\n",
      "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.7899 - f1_score: 0.6391 - loss: 0.4351 - precision: 0.5375 - recall: 0.8232\n",
      "\n",
      "測試集績效\n",
      "Loss: 0.4354257583618164\n",
      "Accuracy: 0.7884036898612976\n",
      "Precision: 0.6347290277481079\n",
      "Recall: 0.5335136651992798\n",
      "F1 Score: 0.82137131690979\n"
     ]
    }
   ],
   "source": [
    "#嘗試k-fold\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 匯入資料\n",
    "columns_name = ['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','income']\n",
    "\n",
    "data_train = pd.read_csv('adult/adult.data', names=columns_name, header=None , na_values=['?'])\n",
    "d_train = pd.DataFrame(data_train)\n",
    "\n",
    "data_test = pd.read_csv('adult/adult.test', names=columns_name, skiprows=1, header=None ,na_values=['?'])\n",
    "d_test = pd.DataFrame(data_test)\n",
    "\n",
    "# 處理遺失值\n",
    "columns_to_check = ['workclass', 'occupation', 'native-country']\n",
    "d_train.replace(\" ?\", np.nan, inplace=True)\n",
    "column_modes = d_train[columns_to_check].mode().iloc[0]\n",
    "d_train.fillna(column_modes, inplace=True)\n",
    "\n",
    "d_test.replace(\" ?\", np.nan, inplace=True)\n",
    "column_modes = d_test[columns_to_check].mode().iloc[0]\n",
    "d_test.fillna(column_modes, inplace=True)\n",
    "\n",
    "# 資料合併\n",
    "d_data = pd.concat([d_train, d_test], axis=0)\n",
    "\n",
    "# 移除無關欄位\n",
    "d_data.drop(['fnlwgt', 'capital-gain', 'capital-loss'], axis=1, inplace=True)\n",
    "\n",
    "# income類別調整\n",
    "income_mapping = {\n",
    "     \" >50K\": \">50K\",\n",
    "    \" >50K.\": \">50K\",\n",
    "    \" <=50K\": \"<=50K\",\n",
    "    \" <=50K.\": \"<=50K\"\n",
    "}\n",
    "for column in ['income']:\n",
    "    d_data[column] = d_data[column].replace(income_mapping)\n",
    "\n",
    "# 類別型態轉成數值\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "d_str = d_data.select_dtypes(include='object')\n",
    "for column in d_str.columns:\n",
    "    d_data[column] = label_encoder.fit_transform(d_data[column])\n",
    "\n",
    "# 切分資料集\n",
    "d_train = d_data[:len(d_train)]\n",
    "d_test = d_data[len(d_train):]\n",
    "\n",
    "# 特徵、類別分離\n",
    "x_train = d_train.drop('income', axis=1)\n",
    "y_train = d_train['income']\n",
    "\n",
    "x_test = d_test.drop('income', axis=1)\n",
    "y_test = d_test['income']\n",
    "\n",
    "# 正規化\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "print('ok')\n",
    "\n",
    "# 定義自定義評估指標\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = tf.reduce_sum(tf.round(tf.clip_by_value(tf.cast(y_true, tf.float32) * tf.cast(y_pred, tf.float32), 0, 1)))\n",
    "    predicted_positives = tf.reduce_sum(tf.round(tf.clip_by_value(tf.cast(y_pred, tf.float32), 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = tf.reduce_sum(tf.round(tf.clip_by_value(tf.cast(y_true, tf.float32) * tf.cast(y_pred, tf.float32), 0, 1)))\n",
    "    possible_positives = tf.reduce_sum(tf.round(tf.clip_by_value(tf.cast(y_true, tf.float32), 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision_val = precision(y_true, y_pred)\n",
    "    recall_val = recall(y_true, y_pred)\n",
    "    f1_val = 2 * ((precision_val * recall_val) / (precision_val + recall_val + K.epsilon()))\n",
    "    return f1_val\n",
    "\n",
    "# 定義神經網路模型\n",
    "def create_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(500, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(layers.Dense(250, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(layers.Dense(125, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy', precision, recall, f1_score])\n",
    "    return model\n",
    "\n",
    "# 使用 k-fold 驗證\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "cv_scores = []\n",
    "train_metrics = None\n",
    "\n",
    "for train_index, val_index in kfold.split(x_train):\n",
    "    model = create_model()\n",
    "    x_fold_train, x_fold_val = x_train[train_index], x_train[val_index]\n",
    "    y_fold_train, y_fold_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    history = model.fit(x_fold_train, y_fold_train, epochs=8, batch_size=64, validation_data=(x_fold_val, y_fold_val))\n",
    "    scores = model.evaluate(x_fold_val, y_fold_val)\n",
    "    cv_scores.append(scores)\n",
    "    # 計算訓練集的績效指標\n",
    "    train_metrics = model.evaluate(x_fold_train, y_fold_train)\n",
    "\n",
    "# 列印最後的訓練集績效指標\n",
    "if train_metrics:\n",
    "    print(\"\\n訓練集績效\")\n",
    "    print(\"Loss:\", train_metrics[0])\n",
    "    print(\"Accuracy:\", train_metrics[1])\n",
    "    print(\"Precision:\", train_metrics[2])\n",
    "    print(\"Recall:\", train_metrics[3])\n",
    "    print(\"F1 Score:\", train_metrics[4])\n",
    "\n",
    "\n",
    "# 列印測試集績效指標\n",
    "test_results = model.evaluate(x_test, y_test)\n",
    "print('\\n測試集績效')\n",
    "print(\"Loss:\", test_results[0])\n",
    "print(\"Accuracy:\", test_results[1])\n",
    "print(\"Precision:\", test_results[2]) \n",
    "print(\"Recall:\", test_results[3])\n",
    "print(\"F1 Score:\", test_results[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfc42bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
